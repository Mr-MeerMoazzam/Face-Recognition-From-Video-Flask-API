{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "525392da",
   "metadata": {},
   "source": [
    "`Hello friends!` Today we will design a web application for face recognition from video. We will use opencv to process the video frames and `face-recognition` library for recognition purpose. The user will submit a form containing input parameter. On the `client side` the uploaded video will be encode as base64 and sent to the server. On the `server side` the uploaded video will be decode, process it frame by frame to find coordinates of detected face if any, store the recognized person name corresponding to the frame in a list, and response to the client with the face coordinates and person name corresponds to each frame. After getting data from server, `client.py` will be display the video to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2977cab1",
   "metadata": {},
   "source": [
    "### What is Face Recognition?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82855a28",
   "metadata": {},
   "source": [
    "A method of recognizing or verifying a person's identification using their face is called `facial recognition`. People can be recognized using facial recognition technology in real-time or in still images and videos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b663ee1",
   "metadata": {},
   "source": [
    "We'll use the `Flask framework` to create a web application in this notebook for face recognition from video. To process the video frames, we'll utilise opencv. A user-submitted form with input parameters will be submitted. Since the primary goal of the project was to become comfortable with the flask web-framework for processing films frame by frame, I picked a very simple design for the front-end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d747383f",
   "metadata": {},
   "source": [
    "`HTTP request-response, error handling, HTTP Routes, and facial recognition` are some of the ideas we employ. Let's take a closer look at how each of them unfolds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217653cf",
   "metadata": {},
   "source": [
    "### Front-end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e877f646",
   "metadata": {},
   "source": [
    "Firstly, the front-end is in two basic HTML files. `index.html` with a button to take video as an input (from which user wants to recognize faces) and jinja template formate to display flash messages. Button in the file posts data to the client side `client.py`. `result.html` with a image source tag to display output frames after pre-processing in the back-end. These files are saved inside the `/src/templates` folder in the project directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468e8527",
   "metadata": {},
   "source": [
    "### index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdb52a6",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/Mr-MeerMoazzam/Face-Recognition-From-Video-Flask-API/blob/main/index.png?raw=true\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddacd0c7",
   "metadata": {},
   "source": [
    "### result.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff164a7",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/Mr-MeerMoazzam/Face-Recognition-From-Video-Flask-API/blob/main/result.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a8b393",
   "metadata": {},
   "source": [
    "### client.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675f1bdc",
   "metadata": {},
   "source": [
    "As for the client side it is a single python script `clien.py` in the project directory. This encode the uploaded video into base64, post to server as json, after getting response from server it shows the resulting video frame by frame. Let's look at parts of the file separately in order to understand it closely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76114745",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/Mr-MeerMoazzam/Face-Recognition-From-Video-Flask-API/blob/main/client1st.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c9eaf",
   "metadata": {},
   "source": [
    "In the code above, we import all necessary modules.\n",
    "\n",
    "Flask is a micro web-framework which works like a bridge between front and back-end. From flask, we import `Response` and `request` modules to handle HTTP response-requests. `render_template` is used to render the HTML file shown before. `cv2` is the module used to perform all the computer vision tasks. from werkzeug.utils we import `secure_filename` to check wether the uploaded file is one from allowabble extensions for video. To work with json data we import `json`. we import `time` for the take delay in the code execution. `os` module provides a portable way of using operating system dependent functionality. \n",
    "\n",
    "In line 14, we instantiate the flask app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b998b835",
   "metadata": {},
   "source": [
    "## HTTP Routes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30267ccb",
   "metadata": {},
   "source": [
    "This is where the front-end communicates with the server. The communication happens in `GET` and `POST` methods through URL routes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fe33eb",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/Mr-MeerMoazzam/Face-Recognition-From-Video-Flask-API/blob/main/client4th.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1524c9e3",
   "metadata": {},
   "source": [
    "`@app. route(‘/’)` is a Python decorator that Flask provides to assign URLs to functions in our app easily. Route ‘/’ is the root URL and `index()` function is called when root URL is entered. ‘index.html’ file is rendered from the function into the webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4b85ad",
   "metadata": {},
   "source": [
    "Route ‘/’ is the root URL and `upload_video()` function is called when user submit a video file. Video file is encoded into base64 and then send the filename and the encoded video data to the server at the URL \"http://127.0.0.1:4300/my_point\" and getting data from server as the coordinates of detected faces and the name of the person in return. After that we save the uploaded video. `result.html` file is rendered from the function into the webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58ce90a",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/Mr-MeerMoazzam/Face-Recognition-From-Video-Flask-API/blob/main/client5th.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e588bbc",
   "metadata": {},
   "source": [
    "`Route ‘/video_feed’` is set as the source for image in the html file. This function returns response chunks of frames yielded by `gen_frames()` on a loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c5c1bd",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aaf096",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/Mr-MeerMoazzam/Face-Recognition-From-Video-Flask-API/blob/main/client2nd.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18388669",
   "metadata": {},
   "source": [
    "`allowed_file()` takes a filename as input and returns a true or false on the allowed video file extensions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8b9778",
   "metadata": {},
   "source": [
    "\n",
    "ALLOWED_EXTENSIONS = set(['mp4','gif','mov','avi','mkv'])\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c9d0dd",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/Mr-MeerMoazzam/Face-Recognition-From-Video-Flask-API/blob/main/client3rd.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a55ce",
   "metadata": {},
   "source": [
    "`gen_frames` is an important function wherein video frame capture, the face detected coordinates and the name of recognized person (that is responded by server side) is being added on each frame captured by the video. First we assign a uploaded video path to `cv2.VideCapture()`. Line 34 captures frames from the camera object. If frame capture is successful,then we draw a rectangle around the face and a name label below the face.\n",
    "\n",
    "Line 52 encodes the frame into the memory buffer and is then converted into an array of bytes. Line 54 yields the frame data in a format required to be sent as a HTTP response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da294785",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/Mr-MeerMoazzam/Face-Recognition-From-Video-Flask-API/blob/main/client6th.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37fb33b",
   "metadata": {},
   "source": [
    "`app.run()` is used to start the flask app in its default address: http://127.0.0.1:8080/. We set a different host and port number by adding `host` and `port` arguments to the function `run` and `debug=True` to enable the debug mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a5dfe4",
   "metadata": {},
   "source": [
    "### server.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35389e56",
   "metadata": {},
   "source": [
    "As for the server side it is a single python script `server.py` in the project directory. It simply takes a video in encoded form, decode it, save it on server, process it frame by frame to find coordinates of detected face if any, store the recognized person name corresponding to the frame in a list, and response to the client with the face coordinates and person name corresponds to each frame.  Let's look at parts of the file separately in order to understand it closely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41be7278",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/Mr-MeerMoazzam/Face-Recognition-From-Video-Flask-API/blob/main/server1.png?raw=true\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d1a872",
   "metadata": {},
   "source": [
    "In the code above, we import all necessary modules.\n",
    "\n",
    "Flask is a micro web-framework which works like a bridge between front and back-end. From flask, we import `Response` and `request` modules to handle HTTP response-requests. `render_template` is used to render the HTML file shown before. `OpenCV` is the module used to perform all the computer vision tasks.`face-recognition` recognize and manipulate faces from Python or from the command line with\n",
    "the world’s simplest face recognition library. It built using `dlib’s` state-of-the-art face recognition. To work with json data we import `json`.\n",
    "In line 10, we instantiate the flask app. After it we save the arrays of known faces encodings and their names correspondingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8fc129",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d6d477",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://github.com/Mr-MeerMoazzam/Face-Recognition-From-Video-Flask-API/blob/main/server2.png?raw=true\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cd9f81",
   "metadata": {},
   "source": [
    "`recognize_face()` takes a numpy image array and a coordinate list as input and returns a name and face location coodinates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac787c9",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/Mr-MeerMoazzam/Face-Recognition-From-Video-Flask-API/blob/main/server4.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ed3ab6",
   "metadata": {},
   "source": [
    "`app.run()` is used to start the flask app in address: http://127.0.0.1:4300/. We set a different host and port number by adding `host` and `port` arguments to the function `run` and `debug=True` to enable the debug mode ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b78ff1",
   "metadata": {},
   "source": [
    "### HTTP Routes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd81b53b",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://github.com/Mr-MeerMoazzam/Face-Recognition-From-Video-Flask-API/blob/main/server3.png?raw=true\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63dc7f8",
   "metadata": {},
   "source": [
    "`Route ‘/my_point’` is the URL and `process_video()` function is called when data is post to server at the URL \"http://127.0.0.1:4300/my_point\". It get the posted data, convert into a dictionary, take encoded video data, decode it, save it on the server. After that it process the video frame by frame and return the processing results to the client. Just for the sake of simplicity, we are using just first five frames of the video for processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
